{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9200af3d-175d-4a69-8d28-04ed3787b347",
   "metadata": {},
   "source": "# Spam Detection Workshop\n## Text Classification for SMS and Email Messages"
  },
  {
   "cell_type": "markdown",
   "id": "03076548",
   "metadata": {},
   "source": "**Learning Objectives:**\nBy completing this workshop, you will be able to:\n- Understand fundamental concepts of Natural Language Processing (NLP)\n- Handle text preprocessing and tokenization strategies\n- Apply feature extraction techniques for text classification\n- Implement and evaluate machine learning models for text data\n- Compare model performance across different datasets and scenarios\n- Understand the challenges of domain transfer in text classification\n\n**Context:**\nSpam detection is a critical application of text classification that helps protect users from unwanted messages. This workshop uses two different datasets (SMS and email messages) to explore how machine learning models perform across different text domains and communication channels.\n\nUnlike numerical data, text requires special preprocessing steps including tokenization, feature extraction, and encoding before machine learning algorithms can process it effectively.\n"
  },
  {
   "cell_type": "markdown",
   "id": "794560d3-3370-4f92-bde4-bd562426d0c6",
   "metadata": {},
   "source": "***\n# 1. Library Setup and Data Loading\n\nLet's start by importing the necessary libraries for text processing and machine learning."
  },
  {
   "cell_type": "code",
   "id": "afc8f167-5477-48a0-8e2a-6abaa421c89b",
   "metadata": {
    "trusted": false,
    "ExecuteTime": {
     "end_time": "2025-11-30T16:56:30.502064Z",
     "start_time": "2025-11-30T16:56:30.494305Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "from mlflow.models import predict\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import string\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from matplotlib.pyplot import plot, show\n",
    "from sklearn.semi_supervised.tests.test_self_training import X_train\n",
    "\n",
    "RANDOM_STATE = 3\n",
    "TRAIN_TEST_SPLIT_SIZE = 0.2"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "id": "cf30c64f-75c7-48b0-9e74-c0e481c190f4",
   "metadata": {},
   "source": "***\n# 2. Read the input data and check its sanity\nWe have two annotated corpora:\n* SMS messages and their classes;\n* email messages and their classes.\n\nUnderstanding the characteristics and quality of our datasets is essential before building models. We need to check for duplicate entries, data imbalance, and basic statistics to ensure robust model training."
  },
  {
   "cell_type": "markdown",
   "id": "4ed5c9f4",
   "metadata": {},
   "source": "## 2.1 Initial Data Loading and Exploration"
  },
  {
   "cell_type": "code",
   "id": "1bc82ade-150e-46d0-9787-4d6f219b0359",
   "metadata": {
    "trusted": false,
    "ExecuteTime": {
     "end_time": "2025-11-30T16:56:31.201156Z",
     "start_time": "2025-11-30T16:56:30.554070Z"
    }
   },
   "source": "    # Load the datasets\nsms_data = pd.read_csv('../data/sms_spam.csv',sep=';')\nemail_data = pd.read_csv('../data/email_spam.csv')\n",
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "id": "1db7a3ca",
   "metadata": {},
   "source": "**Exercise:** Check for duplicate entries and data quality issues\n\nDuplicate entries can artificially inflate performance if the same message appears in both training and test sets. Removing duplicates ensures fair evaluation and prevents data leakage.\n\n**Documentation references:**\n- [pandas.DataFrame.drop_duplicates()](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.drop_duplicates.html)\n- [Data quality assessment](https://pandas.pydata.org/docs/user_guide/duplicates.html)\n\nUse the `drop_duplicates()` method to remove any duplicate entries from both datasets. Set `inplace=True` and `ignore_index=True` to modify the datasets directly and reset row indices."
  },
  {
   "metadata": {
    "trusted": false,
    "ExecuteTime": {
     "end_time": "2025-11-30T16:56:31.288184Z",
     "start_time": "2025-11-30T16:56:31.216176Z"
    }
   },
   "cell_type": "code",
   "source": "print(sms_data.duplicated().sum())\nprint(email_data.duplicated().sum())",
   "id": "d7a00a2e4fa44dd0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "404\n",
      "0\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "trusted": false,
    "ExecuteTime": {
     "end_time": "2025-11-30T16:56:31.362753Z",
     "start_time": "2025-11-30T16:56:31.304296Z"
    }
   },
   "cell_type": "code",
   "source": "# TODO Check for the existence of duplicate entries and eliminate them if necessary.\nsms_data.drop_duplicates(inplace=True, ignore_index=True)\nemail_data.drop_duplicates(inplace=True, ignore_index=True)",
   "id": "9ee15ad706ee4fc4",
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "id": "af31a508",
   "metadata": {
    "trusted": false,
    "ExecuteTime": {
     "end_time": "2025-11-30T16:56:31.382866Z",
     "start_time": "2025-11-30T16:56:31.377499Z"
    }
   },
   "source": "# Extract messages and labels for easier handling\nsms_messages = sms_data[\"message\"]\nsms_labels = sms_data[\"label\"]\nemail_messages = email_data[\"message\"]\nemail_labels = email_data[\"label\"]",
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "id": "7717e198",
   "metadata": {},
   "source": "## 2.2 Dataset Splitting Strategies\n\nDifferent experimental scenarios require different data splitting approaches. We'll implement four strategies to explore various aspects of text classification performance:\n\n1. **Train/Test on SMS**: Standard evaluation within SMS domain\n2. **Train/Test on Email**: Standard evaluation within email domain  \n3. **Transfer Learning**: Train on SMS, test on email (domain adaptation)\n4. **Combined Training**: Train and test on merged datasets"
  },
  {
   "cell_type": "markdown",
   "id": "87ab9253",
   "metadata": {},
   "source": "**Exercise:** Implement SMS dataset splitting function\n\nStandard train-test splitting allows us to evaluate model performance within the SMS domain. This provides a baseline for comparison with other scenarios.\n\n**Documentation references:**\n- [train_test_split documentation](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html)\n- [Random state for reproducibility](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html#sklearn.model_selection.train_test_split)"
  },
  {
   "cell_type": "code",
   "id": "13940249-b044-40d8-87c6-e1af46a82c55",
   "metadata": {
    "trusted": false,
    "ExecuteTime": {
     "end_time": "2025-11-30T16:56:31.439657Z",
     "start_time": "2025-11-30T16:56:31.433641Z"
    }
   },
   "source": "# TODO Implement the function\ndef train_eval_sms():\n    \"\"\"\n    Split SMS dataset into training and testing sets.\n    \n    Creates a standard train-test split for SMS spam detection evaluation.\n    Uses stratified sampling to maintain class distribution across splits.\n    \n    Returns\n    -------\n    tuple\n        Tuple containing (train_messages, test_messages, train_labels, test_labels)\n        \n    Notes\n    -----\n    Uses global TRAIN_TEST_SPLIT_SIZE and RANDOM_STATE for consistency\n    across all experiments.\n    \"\"\"\n    return train_test_split(sms_messages, sms_labels, test_size= TRAIN_TEST_SPLIT_SIZE, random_state=RANDOM_STATE, stratify= sms_labels)\n\n",
   "outputs": [],
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "id": "cbd08776",
   "metadata": {},
   "source": "**Exercise:** Implement email dataset splitting function\n\nSimilar to SMS splitting, this function enables evaluation within the email domain to establish baseline performance for email spam detection."
  },
  {
   "cell_type": "code",
   "id": "56127f57-c39f-4402-8a96-3dd91c1a960d",
   "metadata": {
    "trusted": false,
    "ExecuteTime": {
     "end_time": "2025-11-30T16:56:31.514774Z",
     "start_time": "2025-11-30T16:56:31.508123Z"
    }
   },
   "source": "# TODO: Implement the function\ndef train_eval_email():\n    \"\"\"\n    Split email dataset into training and testing sets.\n    \n    Creates a standard train-test split for email spam detection evaluation.\n    Maintains consistent splitting parameters with SMS evaluation for fair comparison.\n    \n    Returns\n    -------\n    tuple\n        Tuple containing (train_messages, test_messages, train_labels, test_labels)\n    \"\"\"\n    return train_test_split(email_messages, email_labels, test_size= TRAIN_TEST_SPLIT_SIZE, random_state=RANDOM_STATE, stratify=email_labels)",
   "outputs": [],
   "execution_count": 8
  },
  {
   "cell_type": "markdown",
   "id": "cdbb0268",
   "metadata": {},
   "source": "**Exercise:** Implement cross-domain transfer function\n\nDomain transfer testing reveals how well models trained on one type of text (SMS) perform on another (email). This scenario is common in real-world applications where training data and deployment contexts differ."
  },
  {
   "cell_type": "code",
   "id": "6d969741-7ddf-4f0b-ad7b-8b2a71aff351",
   "metadata": {
    "trusted": false,
    "ExecuteTime": {
     "end_time": "2025-11-30T16:56:31.573472Z",
     "start_time": "2025-11-30T16:56:31.566012Z"
    }
   },
   "source": "# TODO: Implement the train_sms_eval_email function to train on SMS data and evaluate on email data\ndef train_sms_eval_email():\n    \"\"\"\n    Prepare data for cross-domain transfer learning experiment.\n    \n    Uses entire SMS dataset for training and entire email dataset for testing.\n    This setup evaluates model generalization across different text domains\n    and communication channels.\n    \n    Returns\n    -------\n    tuple\n        Tuple containing (train_messages, test_messages, train_labels, test_labels)\n        where training data comes from SMS and testing data from email\n        \n    Notes\n    -----\n    No random splitting is performed as we use complete datasets for \n    cross-domain evaluation.\n    \"\"\"\n    return sms_messages, email_messages, sms_labels, email_labels\n",
   "outputs": [],
   "execution_count": 9
  },
  {
   "cell_type": "markdown",
   "id": "883bead5",
   "metadata": {},
   "source": "**Exercise:** Implement combined dataset function\n\nTraining on combined data tests whether mixing domains improves overall performance and provides insights into dataset complementarity for spam detection.\n\n**Documentation references:**\n- [pandas.concat() for combining datasets](https://pandas.pydata.org/docs/reference/api/pandas.concat.html)"
  },
  {
   "cell_type": "code",
   "id": "9de8781a-628f-4321-bdf7-c8887f07dd2c",
   "metadata": {
    "trusted": false,
    "ExecuteTime": {
     "end_time": "2025-11-30T16:56:31.629416Z",
     "start_time": "2025-11-30T16:56:31.621226Z"
    }
   },
   "source": "# TODO: Implement the train_eval_combined function to combine SMS and email data for training and testing\ndef train_eval_combined():\n    \"\"\"\n    Combine SMS and email datasets for unified training and testing.\n    \n    Merges both datasets and creates a mixed train-test split. This approach\n    evaluates whether combining different text domains improves overall\n    spam detection performance.\n    \n    Returns\n    -------\n    tuple\n        Tuple containing (train_messages, test_messages, train_labels, test_labels)\n        from the combined dataset\n        \n    Notes\n    -----\n    Uses pandas.concat to merge datasets while preserving all data points.\n    Maintains class balance across the combined dataset.\n    \"\"\"\n    all_messages = pd.concat([sms_messages, email_messages], ignore_index=True)\n    all_labels = pd.concat([sms_labels, email_labels], ignore_index=True)\n\n    return train_test_split(all_messages, all_labels, test_size=TRAIN_TEST_SPLIT_SIZE, random_state=RANDOM_STATE, stratify=all_labels)",
   "outputs": [],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "id": "5178db71-e7a9-46cb-a068-66d7d11ada72",
   "metadata": {
    "trusted": false,
    "ExecuteTime": {
     "end_time": "2025-11-30T16:56:31.729387Z",
     "start_time": "2025-11-30T16:56:31.702455Z"
    }
   },
   "source": "# Initialize with combined dataset for demonstration\ntraining_messages, testing_messages, training_labels, testing_labels = train_eval_combined()",
   "outputs": [],
   "execution_count": 11
  },
  {
   "cell_type": "markdown",
   "id": "65393c14-4cb2-4525-9a1f-5aaddb126b62",
   "metadata": {},
   "source": "***\n# 3. Data Balancing and Class Distribution\n\nClass imbalance is a common problem in spam detection where spam messages are typically much less frequent than legitimate messages. Imbalanced datasets can lead to biased models that perform poorly on minority classes. We need to address this issue to ensure fair evaluation and robust model performance."
  },
  {
   "cell_type": "markdown",
   "id": "9e37f460",
   "metadata": {},
   "source": "## 3.1 Class Imbalance Detection and Correction\n\nBalanced training data ensures that models learn both spam and non-spam patterns equally well. Oversampling the minority class is a simple and effective approach for text classification.\n\n**Documentation references:**\n- [pandas.DataFrame.sample()](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.sample.html)\n- [Class imbalance handling techniques](https://scikit-learn.org/stable/modules/generated/sklearn.utils.resample.html)"
  },
  {
   "cell_type": "code",
   "id": "110b2568-f3a6-440e-96d9-adc9d398f7ee",
   "metadata": {
    "trusted": false,
    "ExecuteTime": {
     "end_time": "2025-12-01T09:32:11.936653Z",
     "start_time": "2025-12-01T09:32:11.727187Z"
    }
   },
   "source": "def balance(training_messages, training_labels):\n    \"\"\"\n    Balance training data by oversampling the minority class.\n    \n    Addresses class imbalance by randomly sampling additional instances\n    from the underrepresented class until both classes have equal frequency.\n    This prevents model bias toward the majority class.\n    \n    Parameters\n    ----------\n    training_messages : pandas.Series\n        Training text messages\n    training_labels : pandas.Series  \n        Corresponding class labels (0 for ham, 1 for spam)\n        \n    Returns\n    -------\n    tuple\n        Tuple containing (balanced_messages, balanced_labels) with equal\n        class representation\n        \n    Notes\n    -----\n    Uses random sampling with replacement to increase minority class size.\n    Preserves original data distribution while achieving balance.\n    \"\"\"\n    print(\"Label counts before balancing:\")\n    print(training_labels.value_counts())\n    \n    counts = training_labels.value_counts()\n    if counts[1] > counts[0]:\n        label_to_oversample = 0\n        diff = counts[1] - counts[0]\n    else:\n        label_to_oversample = 1\n        diff = counts[0] - counts[1]\n    \n    training_data = pd.concat([training_messages, training_labels], axis=1)\n    draw_from = training_data[training_data[\"label\"] == label_to_oversample]\n    \n    for i in range(diff):\n        sample = draw_from.sample(random_state=RANDOM_STATE)\n        training_data = pd.concat([training_data, sample])\n    \n    training_messages = training_data[\"message\"]\n    training_labels = training_data[\"label\"]\n    \n    print(\"Label counts after balancing:\")\n    print(training_labels.value_counts())\n    return training_messages, training_labels",
   "outputs": [],
   "execution_count": 27
  },
  {
   "cell_type": "markdown",
   "id": "5c7ffd32",
   "metadata": {},
   "source": "**Exercise:** Apply balancing to training data\n\nCheck if the current training data is balanced and apply correction if needed. Balanced training data is crucial for fair model evaluation and optimal performance on both classes."
  },
  {
   "cell_type": "code",
   "id": "3f32b2a8-03ea-415a-9581-a77dc9487f09",
   "metadata": {
    "trusted": false,
    "ExecuteTime": {
     "end_time": "2025-12-01T09:32:20.759083Z",
     "start_time": "2025-12-01T09:32:15.130085Z"
    }
   },
   "source": [
    "# TODO: Check if our training data is balanced and apply balancing if necessary\n",
    "training_messages, training_labels = balance(training_messages, training_labels)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label counts before balancing:\n",
      "label\n",
      "0    6885\n",
      "1    1896\n",
      "Name: count, dtype: int64\n",
      "Label counts after balancing:\n",
      "label\n",
      "0    6885\n",
      "1    6885\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "execution_count": 28
  },
  {
   "cell_type": "markdown",
   "id": "287b2416-cadd-40ea-a748-b744e88f0386",
   "metadata": {},
   "source": "***\n# 4. Text Preprocessing and Feature Extraction\n\n## 4.1 Understanding Tokenization Strategies\n\nWe will take the simplest approach possible: our input features will be the most frequent words and their frequencies. The idea is that the words that appear frequently in a document are characteristic of its content, and thus of its spam-ness.\n\nThe **CountVectorizer** class of scikit-learn will do exactly this for us. It first counts word frequencies across *all* messages, in order to find the overall most frequent ones. Then, it counts the occurrences of these most frequent words in each message, computing a frequency vector per message, where each dimension of the vector corresponds to a frequent word.\n\nFirstly, what does *most frequent word* mean? We will define a threshold, which we will call the **number of features**.\n\nSecondly, what is a word? *Word* is not a term from linguistics, it has no scientific definition.\n* Is \"hazelnuts\" one word, two words, or three words? \"hazel\", \"nut\", and \"-s\" are what linguists call *morphemes*: the elementary units of meaning, but in common language \"hazelnuts\" would be considered as a single word.\n* Is \"$12.50\" a single word? It consists of a currency symbol and a rational number.\n* Is \"Joe's\" one or two words?\n* etc.\n\nA pragmatic choice is not to use the term \"word\" but rather the term \"token\". A token can be whatever unit into which we decide to split our input text. We call **tokenization** the process of splitting a text into tokens. **Beware: the choice of splitting rule will determine the performance of downstream tasks.** CountVectorizer has a **token_pattern** parameter that takes a regular expression as an input string. Instead of blindly trusting whatever default tokenization method offered by CountVectorizer, let us define our own rule. A few possibilities:\n* split by whitespace;\n* split by whitespace or punctuation;\n* keep only tokens that contain letters or digits;\n* keep only tokens of length > X (where you choose X);\n* etc.\n\nFurthermore, it is common to perform additional preprocessing to the input text, always depending on the requirements of the downstream task:\n* in some cases, converting to all-lowercase may improve results (e.g. \"WIN\" and \"win\" are collapsed into a single feature), but it may also result in losing useful information (is all-caps characteristic of spam?);\n* in bag-of-word models, removing so-called *stop words* helps eliminate frequent grammatical words that bear little relevant meaning (e.g. articles, pronouns, modal verbs, prepositions). Beware, as models that rely on syntax (i.e. phrases) do need grammar words: stop words should not be eliminated systematically.\n\nCountVectorizer is a powerful tool that has built-in support for both lowercase conversion and removal of English stop words, so you do not need to implement these preprocessing operations by hand. \n\n**Documentation references:**\n- [Text feature extraction guide](https://scikit-learn.org/stable/modules/feature_extraction.html#text-feature-extraction)\n- [CountVectorizer documentation](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html)\n- [Regular expressions for tokenization](https://docs.python.org/3/library/re.html#regular-expression-syntax)"
  },
  {
   "cell_type": "markdown",
   "id": "f7930247",
   "metadata": {},
   "source": "**Configure tokenization and feature extraction parameters**\n\nThe `token_pattern` parameter controls how text is split into tokens. Different patterns can significantly impact model performance by determining which linguistic units are considered as features."
  },
  {
   "cell_type": "code",
   "id": "7d0e8330-b878-41a8-b49f-64bfa3d4b75f",
   "metadata": {
    "trusted": false,
    "ExecuteTime": {
     "end_time": "2025-12-01T09:52:04.580901Z",
     "start_time": "2025-12-01T09:52:04.487643Z"
    }
   },
   "source": "# Define the regular expression that extracts tokens.\n# Within the regex, there should be exactly one parenthesised expression\n# that will capture the token to be extracted.\n\n# The following example extracts series of non-whitespace characters.\nTOKEN_REGEX = r\"(\\S+)\"\nNB_FEATURES = 5000\n",
   "outputs": [],
   "execution_count": 29
  },
  {
   "cell_type": "markdown",
   "id": "6b09c3ef",
   "metadata": {},
   "source": "**Exercise:** Initialize text vectorization with CountVectorizer\n\nCountVectorizer converts text documents into numerical feature vectors by counting token occurrences. It first builds a vocabulary from the most frequent tokens, then represents each document as a vector of token counts.\n\n**Key parameters:**\n- `max_features`: Limits vocabulary size to most frequent tokens\n- `token_pattern`: Regular expression defining what constitutes a token\n- `lowercase`: Whether to convert text to lowercase before tokenization\n- `stop_words`: Whether to remove common English stop words\n\nInitialize CountVectorizer with the defined parameters to prepare for feature extraction."
  },
  {
   "cell_type": "code",
   "id": "811a8d0d",
   "metadata": {
    "trusted": false,
    "ExecuteTime": {
     "end_time": "2025-12-01T09:56:34.089305Z",
     "start_time": "2025-12-01T09:56:33.904596Z"
    }
   },
   "source": [
    "# TODO Call CountVectorizer with the two parameters above\n",
    "vectorizer = CountVectorizer(max_features=NB_FEATURES, token_pattern=TOKEN_REGEX, lowercase=True, stop_words='english')"
   ],
   "outputs": [],
   "execution_count": 30
  },
  {
   "cell_type": "markdown",
   "id": "12f8169d",
   "metadata": {},
   "source": "## 4.2 Feature Matrix Creation\n\nThe vectorization process has two phases:\n- **Fit**: Analyzes training text to build vocabulary of most frequent tokens\n- **Transform**: Converts text documents into numerical feature vectors using the learned vocabulary\n\n**Documentation references:**\n- [Fit vs Transform in scikit-learn](https://scikit-learn.org/stable/modules/preprocessing.html#preprocessing)\n- [Feature extraction workflow](https://scikit-learn.org/stable/modules/feature_extraction.html#the-bag-of-words-representation)"
  },
  {
   "cell_type": "markdown",
   "id": "e72f70e7",
   "metadata": {},
   "source": "**Exercise:** Create feature matrices for training and testing\n\nUse `fit_transform()` on training data to learn vocabulary and create features simultaneously:\n- \"fit\" computes the *vocabulary* consisting of the most frequent tokens.\n- \"transform\" computes the *frequencies* of tokens in the vocabulary, which will be our input features. \n\nUse `transform()` on testing data to convert it using the same vocabulary learned from training, ensuring consistency between training and testing representations."
  },
  {
   "cell_type": "code",
   "id": "8da1c0f6",
   "metadata": {
    "trusted": false,
    "ExecuteTime": {
     "end_time": "2025-12-01T10:00:49.391623Z",
     "start_time": "2025-12-01T10:00:46.172561Z"
    }
   },
   "source": [
    "# TODO Fit and transform with the vectorizer on the training messages\n",
    "X_train = vectorizer.fit_transform(training_messages)"
   ],
   "outputs": [],
   "execution_count": 31
  },
  {
   "cell_type": "code",
   "id": "54c7da5d",
   "metadata": {
    "trusted": false,
    "ExecuteTime": {
     "end_time": "2025-12-01T10:00:51.858051Z",
     "start_time": "2025-12-01T10:00:51.583811Z"
    }
   },
   "source": [
    "# TODO Do transform with the vectorizer on the testing messages\n",
    "X_test =vectorizer.transform(testing_messages)"
   ],
   "outputs": [],
   "execution_count": 32
  },
  {
   "cell_type": "markdown",
   "id": "53de2265-bc54-4224-9c79-f6cc226432ba",
   "metadata": {},
   "source": "***\n# 5. Model Training with Logistic Regression\n\nWe will use one of the simplest and fastest machine learning models that exist: a **logistic regression classifier**.\n\nLogistic regression is a binary classifier, which suits our task well. The only input hyperparameter we will use is the number of iterations.\n\nWe could also use other classifiers, such as an SVM, but the goal of this lab is to get familiar with a few fundamental notions of natural language processing, not to find the best machine learning method."
  },
  {
   "cell_type": "markdown",
   "id": "cec15717",
   "metadata": {},
   "source": "## 5.1 Model Configuration and Training\n\n**Documentation references:**\n- [Logistic Regression documentation](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html)\n- [Text classification with scikit-learn](https://scikit-learn.org/stable/tutorial/text_analytics/working_with_text_data.html)"
  },
  {
   "cell_type": "code",
   "id": "75dbd6df-fe69-4ce0-b235-c3be76aefb80",
   "metadata": {
    "trusted": false,
    "ExecuteTime": {
     "end_time": "2025-12-01T10:01:58.417002Z",
     "start_time": "2025-12-01T10:01:58.399986Z"
    }
   },
   "source": "# Model hyperparameters\nNB_ITERATIONS = 1000",
   "outputs": [],
   "execution_count": 33
  },
  {
   "cell_type": "markdown",
   "id": "dfd17e26",
   "metadata": {},
   "source": "**Exercise:** Initialize and train the logistic regression model\n\nConfigure Logistic Regression with sufficient iterations to ensure convergence on high-dimensional text features. Train the model on the preprocessed feature matrix to learn patterns distinguishing spam from legitimate messages."
  },
  {
   "metadata": {
    "trusted": false,
    "ExecuteTime": {
     "end_time": "2025-12-01T10:09:28.652659Z",
     "start_time": "2025-12-01T10:09:28.637430Z"
    }
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": 36,
   "source": [
    "# TODO Instantiate a logistic regression model with the number of iterations as an input hyperparameter\n",
    "model = LogisticRegression(max_iter=NB_ITERATIONS, random_state=RANDOM_STATE)"
   ],
   "id": "a30bc582"
  },
  {
   "cell_type": "code",
   "id": "d71edb22",
   "metadata": {
    "trusted": false,
    "ExecuteTime": {
     "end_time": "2025-12-01T10:10:14.146293Z",
     "start_time": "2025-12-01T10:10:12.786105Z"
    }
   },
   "source": [
    "# TODO Train the model\n",
    "model.fit(X_train, training_labels)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=1000, random_state=3)"
      ],
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  display: none;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  overflow: visible;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".estimator-table summary {\n",
       "    padding: .5rem;\n",
       "    font-family: monospace;\n",
       "    cursor: pointer;\n",
       "}\n",
       "\n",
       ".estimator-table details[open] {\n",
       "    padding-left: 0.1rem;\n",
       "    padding-right: 0.1rem;\n",
       "    padding-bottom: 0.3rem;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table {\n",
       "    margin-left: auto !important;\n",
       "    margin-right: auto !important;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(odd) {\n",
       "    background-color: #fff;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(even) {\n",
       "    background-color: #f6f6f6;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:hover {\n",
       "    background-color: #e0e0e0;\n",
       "}\n",
       "\n",
       ".estimator-table table td {\n",
       "    border: 1px solid rgba(106, 105, 104, 0.232);\n",
       "}\n",
       "\n",
       ".user-set td {\n",
       "    color:rgb(255, 94, 0);\n",
       "    text-align: left;\n",
       "}\n",
       "\n",
       ".user-set td.value pre {\n",
       "    color:rgb(255, 94, 0) !important;\n",
       "    background-color: transparent !important;\n",
       "}\n",
       "\n",
       ".default td {\n",
       "    color: black;\n",
       "    text-align: left;\n",
       "}\n",
       "\n",
       ".user-set td i,\n",
       ".default td i {\n",
       "    color: black;\n",
       "}\n",
       "\n",
       ".copy-paste-icon {\n",
       "    background-image: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCA0NDggNTEyIj48IS0tIUZvbnQgQXdlc29tZSBGcmVlIDYuNy4yIGJ5IEBmb250YXdlc29tZSAtIGh0dHBzOi8vZm9udGF3ZXNvbWUuY29tIExpY2Vuc2UgLSBodHRwczovL2ZvbnRhd2Vzb21lLmNvbS9saWNlbnNlL2ZyZWUgQ29weXJpZ2h0IDIwMjUgRm9udGljb25zLCBJbmMuLS0+PHBhdGggZD0iTTIwOCAwTDMzMi4xIDBjMTIuNyAwIDI0LjkgNS4xIDMzLjkgMTQuMWw2Ny45IDY3LjljOSA5IDE0LjEgMjEuMiAxNC4xIDMzLjlMNDQ4IDMzNmMwIDI2LjUtMjEuNSA0OC00OCA0OGwtMTkyIDBjLTI2LjUgMC00OC0yMS41LTQ4LTQ4bDAtMjg4YzAtMjYuNSAyMS41LTQ4IDQ4LTQ4ek00OCAxMjhsODAgMCAwIDY0LTY0IDAgMCAyNTYgMTkyIDAgMC0zMiA2NCAwIDAgNDhjMCAyNi41LTIxLjUgNDgtNDggNDhMNDggNTEyYy0yNi41IDAtNDgtMjEuNS00OC00OEwwIDE3NmMwLTI2LjUgMjEuNS00OCA0OC00OHoiLz48L3N2Zz4=);\n",
       "    background-repeat: no-repeat;\n",
       "    background-size: 14px 14px;\n",
       "    background-position: 0;\n",
       "    display: inline-block;\n",
       "    width: 14px;\n",
       "    height: 14px;\n",
       "    cursor: pointer;\n",
       "}\n",
       "</style><body><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(max_iter=1000, random_state=3)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>LogisticRegression</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.7/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"\">\n",
       "        <div class=\"estimator-table\">\n",
       "            <details>\n",
       "                <summary>Parameters</summary>\n",
       "                <table class=\"parameters-table\">\n",
       "                  <tbody>\n",
       "                    \n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('penalty',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">penalty&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;l2&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('dual',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">dual&nbsp;</td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('tol',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">tol&nbsp;</td>\n",
       "            <td class=\"value\">0.0001</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('C',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">C&nbsp;</td>\n",
       "            <td class=\"value\">1.0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('fit_intercept',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">fit_intercept&nbsp;</td>\n",
       "            <td class=\"value\">True</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('intercept_scaling',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">intercept_scaling&nbsp;</td>\n",
       "            <td class=\"value\">1</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('class_weight',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">class_weight&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('random_state',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">random_state&nbsp;</td>\n",
       "            <td class=\"value\">3</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('solver',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">solver&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;lbfgs&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_iter',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">max_iter&nbsp;</td>\n",
       "            <td class=\"value\">1000</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('multi_class',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">multi_class&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;deprecated&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('verbose',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">verbose&nbsp;</td>\n",
       "            <td class=\"value\">0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('warm_start',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">warm_start&nbsp;</td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('n_jobs',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">n_jobs&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('l1_ratio',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">l1_ratio&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "                  </tbody>\n",
       "                </table>\n",
       "            </details>\n",
       "        </div>\n",
       "    </div></div></div></div></div><script>function copyToClipboard(text, element) {\n",
       "    // Get the parameter prefix from the closest toggleable content\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${text}` : text;\n",
       "\n",
       "    const originalStyle = element.style;\n",
       "    const computedStyle = window.getComputedStyle(element);\n",
       "    const originalWidth = computedStyle.width;\n",
       "    const originalHTML = element.innerHTML.replace('Copied!', '');\n",
       "\n",
       "    navigator.clipboard.writeText(fullParamName)\n",
       "        .then(() => {\n",
       "            element.style.width = originalWidth;\n",
       "            element.style.color = 'green';\n",
       "            element.innerHTML = \"Copied!\";\n",
       "\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        })\n",
       "        .catch(err => {\n",
       "            console.error('Failed to copy:', err);\n",
       "            element.style.color = 'red';\n",
       "            element.innerHTML = \"Failed!\";\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        });\n",
       "    return false;\n",
       "}\n",
       "\n",
       "document.querySelectorAll('.fa-regular.fa-copy').forEach(function(element) {\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const paramName = element.parentElement.nextElementSibling.textContent.trim();\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${paramName}` : paramName;\n",
       "\n",
       "    element.setAttribute('title', fullParamName);\n",
       "});\n",
       "</script></body>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 37
  },
  {
   "cell_type": "markdown",
   "id": "b612598a-c191-409b-a193-98eedda7cde7",
   "metadata": {},
   "source": "***\n# 6. Model Evaluation and Metrics\n\nEvaluation metrics provide different perspectives on model performance. For spam detection, we need to understand not just overall accuracy but also how well the model identifies spam (precision) and how many spam messages it catches (recall)."
  },
  {
   "cell_type": "markdown",
   "id": "f164e9b6-2e23-466d-a90a-c2c37dc29406",
   "metadata": {},
   "source": "**Confusion Matrix Concepts:**\n\n|                | Predicted Ham | Predicted Spam |\n|----------------|:------------:|:-------------:|\n| **Actual Ham** | TN           | FP            |\n| **Actual Spam**| FN           | TP            |\n\nWhere:\n- **True Positives (TP)**: Correctly identified spam\n- **True Negatives (TN)**: Correctly identified ham  \n- **False Positives (FP)**: Ham incorrectly labeled as spam\n- **False Negatives (FN)**: Spam incorrectly labeled as ham\n\n**Documentation references:**\n- [Classification metrics guide](https://scikit-learn.org/stable/modules/model_evaluation.html#classification-metrics)\n- [Confusion matrix interpretation](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html)"
  },
  {
   "cell_type": "markdown",
   "id": "bc5bb110-f3f3-4393-a17d-fad71b21d336",
   "metadata": {},
   "source": "### 6.1.1 Accuracy Implementation\n\n**Exercise:** Implement accuracy calculation from scratch\n\nAccuracy measures the proportion of correct predictions (both spam and ham) out of all predictions. While intuitive, accuracy can be misleading with imbalanced datasets where a model could achieve high accuracy by always predicting the majority class.\n\n**Formula:** Accuracy = (TP + TN) / (TP + TN + FP + FN)"
  },
  {
   "cell_type": "code",
   "id": "bd934b23-f400-4d83-910e-613893baa830",
   "metadata": {
    "trusted": false,
    "ExecuteTime": {
     "end_time": "2025-12-01T10:13:06.678615Z",
     "start_time": "2025-12-01T10:13:06.621350Z"
    }
   },
   "source": [
    "# TODO: Compute accuracy by comparing truth and predicted labels\n",
    "def accuracy_score(truth, pred):\n",
    "    \"\"\"\n",
    "    Calculate accuracy as the proportion of correct predictions.\n",
    "    \n",
    "    Accuracy measures overall correctness but may not reflect performance\n",
    "    on individual classes, especially with imbalanced datasets.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    truth : array-like\n",
    "        Ground truth labels (0 for ham, 1 for spam)\n",
    "    pred : array-like  \n",
    "        Predicted labels from the model\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        Accuracy score between 0 and 1, where 1 indicates perfect accuracy\n",
    "        \n",
    "    Notes\n",
    "    -----\n",
    "    Accuracy alone may be misleading for imbalanced datasets where\n",
    "    a model could achieve high accuracy by always predicting the majority class.\n",
    "    \"\"\"\n",
    "    return (truth == pred).sum() / len(truth)\n"
   ],
   "outputs": [],
   "execution_count": 38
  },
  {
   "cell_type": "markdown",
   "id": "78ef238a-4513-4957-b39c-af2758a4cba3",
   "metadata": {},
   "source": "### 6.1.2 Precision Implementation\n\n**Exercise:** Implement precision calculation from scratch\n\nPrecision measures the proportion of predicted spam that is actually spam. High precision means few false alarms (legitimate messages incorrectly flagged as spam), which is crucial for user experience.\n\n**Formula:** Precision = TP / (TP + FP)\n\n**Documentation references:**\n- [Precision definition](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.precision_score.html)"
  },
  {
   "cell_type": "code",
   "id": "c071a9a1-926b-4804-b850-1b23df8115fd",
   "metadata": {
    "trusted": false,
    "ExecuteTime": {
     "end_time": "2025-12-01T10:15:28.807332Z",
     "start_time": "2025-12-01T10:15:28.790610Z"
    }
   },
   "source": [
    "# TODO: Compute precision by calculating true positives and false positives\n",
    "def precision_score(truth, pred, pos_label):\n",
    "    \"\"\"\n",
    "    Calculate precision for the positive class (spam).\n",
    "    \n",
    "    Precision measures the proportion of predicted spam messages that are\n",
    "    actually spam. High precision indicates few false positive errors\n",
    "    (legitimate messages incorrectly classified as spam).\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    truth : array-like\n",
    "        Ground truth labels\n",
    "    pred : array-like\n",
    "        Predicted labels from the model  \n",
    "    pos_label : int or str\n",
    "        Label that represents the positive class (spam)\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        Precision score between 0 and 1, where 1 indicates perfect precision\n",
    "        \n",
    "    Notes\n",
    "    -----\n",
    "    Precision is especially important in spam detection to minimize\n",
    "    false positives that could cause users to miss important messages.\n",
    "    \"\"\"\n",
    "    t = np.array(truth)\n",
    "    p = np.array(pred)\n",
    "\n",
    "    tp = ((t == pos_label) & (p == pos_label)).sum()\n",
    "    fp = ((t != pos_label) & (p == pos_label)).sum()\n",
    "\n",
    "    if (tp + fp) == 0:\n",
    "        return 0.0\n",
    "    return (tp) / (tp + fp)"
   ],
   "outputs": [],
   "execution_count": 40
  },
  {
   "cell_type": "markdown",
   "id": "5b8a92b4-73f8-4506-b436-65ab371c7af0",
   "metadata": {},
   "source": "### 6.1.3 Recall Implementation\n\n**Exercise:** Implement recall calculation from scratch\n\nRecall measures the proportion of actual spam that the model correctly identifies. High recall means the model catches most spam messages, which is important for protecting users from unwanted content.\n\n**Formula:** Recall = TP / (TP + FN)\n\n**Documentation references:**\n- [Recall definition](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.recall_score.html)"
  },
  {
   "cell_type": "code",
   "id": "9bef05c6-3911-41c6-a943-81c92aa1d2c6",
   "metadata": {
    "trusted": false,
    "ExecuteTime": {
     "end_time": "2025-12-01T10:17:00.149403Z",
     "start_time": "2025-12-01T10:17:00.141001Z"
    }
   },
   "source": [
    "# TODO: Compute recall by calculating true positives and false negatives\n",
    "def recall_score(truth, pred, pos_label):\n",
    "    \"\"\"\n",
    "    Calculate recall for the positive class (spam).\n",
    "    \n",
    "    Recall measures the proportion of actual spam messages that the model\n",
    "    correctly identifies. High recall indicates the model catches most\n",
    "    spam with few false negative errors.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    truth : array-like\n",
    "        Ground truth labels\n",
    "    pred : array-like\n",
    "        Predicted labels from the model\n",
    "    pos_label : int or str  \n",
    "        Label that represents the positive class (spam)\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        Recall score between 0 and 1, where 1 indicates perfect recall\n",
    "        \n",
    "    Notes\n",
    "    -----\n",
    "    Recall is crucial in spam detection to ensure most unwanted messages\n",
    "    are filtered out, protecting users from spam content.\n",
    "    \"\"\"\n",
    "    t = np.array(truth)\n",
    "    p = np.array(pred)\n",
    "\n",
    "    tp = ((t == pos_label) & (p == pos_label)).sum()\n",
    "    fn = ((t == pos_label) & (p != pos_label)).sum()\n",
    "\n",
    "    if (tp + fn) == 0:\n",
    "        return 0.0\n",
    "    return (tp) / (tp + fn)\n"
   ],
   "outputs": [],
   "execution_count": 41
  },
  {
   "cell_type": "markdown",
   "id": "dc39a571-205b-4e4c-a707-5411ffb9e6de",
   "metadata": {},
   "source": "## 6.2 Model Prediction and Performance Analysis\n\n**Exercise:** Generate predictions and calculate comprehensive metrics\n\nUse the trained model to make predictions on the test set, then calculate all three metrics to get a complete picture of model performance. Compare these metrics to understand the trade-offs between accuracy, precision, and recall."
  },
  {
   "cell_type": "code",
   "id": "5af8cfc4-34a6-440d-9681-7931132e66da",
   "metadata": {
    "trusted": false,
    "ExecuteTime": {
     "end_time": "2025-12-01T10:20:40.733847Z",
     "start_time": "2025-12-01T10:20:40.635801Z"
    }
   },
   "source": [
    "# TODO Generate predictions using the trained model\n",
    "predictions = model.predict(X_test)"
   ],
   "outputs": [],
   "execution_count": 44
  },
  {
   "cell_type": "code",
   "id": "43661709",
   "metadata": {
    "trusted": false,
    "ExecuteTime": {
     "end_time": "2025-12-01T10:20:57.138212Z",
     "start_time": "2025-12-01T10:20:57.128777Z"
    }
   },
   "source": [
    "# TODO Calculate all performance metrics\n",
    "acc = accuracy_score(testing_labels, predictions)\n",
    "prec = precision_score(testing_labels, predictions, pos_label=1)\n",
    "rec = recall_score(testing_labels, predictions, pos_label=1)"
   ],
   "outputs": [],
   "execution_count": 47
  },
  {
   "cell_type": "code",
   "id": "39158736",
   "metadata": {
    "trusted": false,
    "ExecuteTime": {
     "end_time": "2025-12-01T10:20:59.613151Z",
     "start_time": "2025-12-01T10:20:59.603872Z"
    }
   },
   "source": "print(\"Accuracy : \" + str(acc))\nprint(\"Precision: \" + str(prec))\nprint(\"Recall   : \" + str(rec))",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.9644808743169399\n",
      "Precision: 0.9479638009049773\n",
      "Recall   : 0.8839662447257384\n"
     ]
    }
   ],
   "execution_count": 48
  },
  {
   "cell_type": "markdown",
   "id": "841ff4b9",
   "metadata": {},
   "source": [
    "\n",
    "***\n",
    "# 7. Experimental Scenarios and Comparative Analysis\n",
    "\n",
    "The following exercises guide you through different experimental scenarios to understand how text classification models perform across domains and datasets. Each scenario reveals different aspects of model generalization and domain adaptation.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-01T10:25:15.441183Z",
     "start_time": "2025-12-01T10:25:15.252770Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def run_experiment(train_msg, test_msg, train_lbl, test_lbl, experiment_name):\n",
    "    print(f\"\\n--- {experiment_name} ---\")\n",
    "\n",
    "    # 1. Équilibrage (Partie 3)\n",
    "    train_msg, train_lbl = balance(train_msg, train_lbl)\n",
    "\n",
    "    # 2. Vectorisation (Partie 4)\n",
    "    # Important : On refait un vectorizer neuf pour chaque expérience\n",
    "    vectorizer = CountVectorizer(max_features=NB_FEATURES, token_pattern=TOKEN_REGEX, stop_words='english')\n",
    "    X_train = vectorizer.fit_transform(train_msg)\n",
    "    X_test = vectorizer.transform(test_msg)\n",
    "\n",
    "    # 3. Entraînement (Partie 5)\n",
    "    model = LogisticRegression(max_iter=NB_ITERATIONS, random_state=RANDOM_STATE)\n",
    "    model.fit(X_train, train_lbl)\n",
    "\n",
    "    # 4. Prédiction et Évaluation (Partie 6)\n",
    "    preds = model.predict(X_test)\n",
    "\n",
    "    acc = accuracy_score(test_lbl, preds)\n",
    "    prec = precision_score(test_lbl, preds, pos_label=1)\n",
    "    rec = recall_score(test_lbl, preds, pos_label=1)\n",
    "\n",
    "    print(f\"Accuracy : {acc:.4f}\")\n",
    "    print(f\"Precision: {prec:.4f}\")\n",
    "    print(f\"Recall   : {rec:.4f}\")"
   ],
   "id": "afaeb7c08340d8e4",
   "outputs": [],
   "execution_count": 49
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 7.1 Single-Domain Experiments\n",
    "\n",
    "**Exercise:** Run experiments on SMS dataset only\n",
    "\n",
    "Modify the data loading section to use `train_eval_sms()` instead of the combined dataset. Observe how the model performs when trained and tested on the same text domain (SMS messages).\n",
    "\n",
    "**Questions to consider:**\n",
    "- How does performance compare to the combined dataset results?\n",
    "- Which metrics show the most significant changes?\n",
    "- What might explain any performance differences?\n",
    "\n",
    "\n",
    "**Exercise:** Run experiments on email dataset only\n",
    "\n",
    "Switch to using `train_eval_email()` to train and test exclusively on email data. Compare results with the SMS-only experiment.\n",
    "\n",
    "**Questions to consider:**\n",
    "- Do emails and SMS messages show similar classification difficulty?\n",
    "- Which dataset appears more challenging for spam detection?\n",
    "- How do the optimal features differ between domains?\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "id": "3b4d3c31a22c3ac7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-01T10:31:17.211677Z",
     "start_time": "2025-12-01T10:31:14.136502Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Chargez les données SMS\n",
    "msg_train, msg_test, lbl_train, lbl_test = train_eval_sms()\n",
    "\n",
    "# Lancez l'expérience\n",
    "run_experiment(msg_train, msg_test, lbl_train, lbl_test, \"Scénario SMS seul\")"
   ],
   "id": "98350784d9dcf0b3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Scénario SMS seul ---\n",
      "Label counts before balancing:\n",
      "label\n",
      "0    3612\n",
      "1     522\n",
      "Name: count, dtype: int64\n",
      "Label counts after balancing:\n",
      "label\n",
      "0    3612\n",
      "1    3612\n",
      "Name: count, dtype: int64\n",
      "Accuracy : 0.9749\n",
      "Precision: 0.9906\n",
      "Recall   : 0.8077\n"
     ]
    }
   ],
   "execution_count": 50
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-01T10:31:38.433645Z",
     "start_time": "2025-12-01T10:31:33.306383Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Chargez les données Email\n",
    "msg_train, msg_test, lbl_train, lbl_test = train_eval_email()\n",
    "\n",
    "# Lancez l'expérience\n",
    "run_experiment(msg_train, msg_test, lbl_train, lbl_test, \"Scénario Email seul\")"
   ],
   "id": "2a39131d57555825",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Scénario Email seul ---\n",
      "Label counts before balancing:\n",
      "label\n",
      "0    3273\n",
      "1    1374\n",
      "Name: count, dtype: int64\n",
      "Label counts after balancing:\n",
      "label\n",
      "0    3273\n",
      "1    3273\n",
      "Name: count, dtype: int64\n",
      "Accuracy : 0.9811\n",
      "Precision: 0.9680\n",
      "Recall   : 0.9680\n"
     ]
    }
   ],
   "execution_count": 51
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 7.2 Cross-Domain Transfer Learning\n",
    "\n",
    "**Exercise:** Train on SMS, evaluate on email dataset\n",
    "\n",
    "Use `train_sms_eval_email()` to explore domain transfer performance. This simulates a realistic scenario where you have labeled data from one domain but need to deploy in another.\n",
    "\n",
    "**Questions to consider:**\n",
    "- How much does performance degrade when transferring across domains?\n",
    "- Which metrics are most affected by domain mismatch?\n",
    "- What linguistic differences between SMS and email might explain the results?"
   ],
   "id": "4a77b23f9b6b6a66"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-01T10:32:01.627649Z",
     "start_time": "2025-12-01T10:31:57.489843Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Chargez les données croisées\n",
    "msg_train, msg_test, lbl_train, lbl_test = train_sms_eval_email()\n",
    "\n",
    "# Lancez l'expérience\n",
    "run_experiment(msg_train, msg_test, lbl_train, lbl_test, \"Scénario Transfert (Train SMS -> Test Email)\")"
   ],
   "id": "9b2d600c13f3b927",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Scénario Transfert (Train SMS -> Test Email) ---\n",
      "Label counts before balancing:\n",
      "label\n",
      "0    4516\n",
      "1     652\n",
      "Name: count, dtype: int64\n",
      "Label counts after balancing:\n",
      "label\n",
      "0    4516\n",
      "1    4516\n",
      "Name: count, dtype: int64\n",
      "Accuracy : 0.7385\n",
      "Precision: 0.5444\n",
      "Recall   : 0.7095\n"
     ]
    }
   ],
   "execution_count": 52
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 7.3 Combined Dataset Analysis\n",
    "\n",
    "**Exercise:** Train and evaluate on combined datasets\n",
    "\n",
    "Return to using `train_eval_combined()` to assess whether mixing domains during training improves overall robustness.\n",
    "\n",
    "**Questions to consider:**\n",
    "- Does combined training improve generalization across both domains?\n",
    "- How do results compare to single-domain experiments?\n",
    "- What are the trade-offs of mixed-domain training?\n",
    "\n"
   ],
   "id": "c71816cd98d87572"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-01T10:32:55.025782Z",
     "start_time": "2025-12-01T10:32:48.125853Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Chargez les données combinées\n",
    "msg_train, msg_test, lbl_train, lbl_test = train_eval_combined()\n",
    "\n",
    "# Lancez l'expérience\n",
    "run_experiment(msg_train, msg_test, lbl_train, lbl_test, \"Scénario Combiné (SMS + Email)\")"
   ],
   "id": "9ce9a40dbcf9d714",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Scénario Combiné (SMS + Email) ---\n",
      "Label counts before balancing:\n",
      "label\n",
      "0    6885\n",
      "1    1896\n",
      "Name: count, dtype: int64\n",
      "Label counts after balancing:\n",
      "label\n",
      "0    6885\n",
      "1    6885\n",
      "Name: count, dtype: int64\n",
      "Accuracy : 0.9645\n",
      "Precision: 0.9480\n",
      "Recall   : 0.8840\n"
     ]
    }
   ],
   "execution_count": 53
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "\n",
    "## 7.4 Add README file\n",
    "\n",
    "**Exercise:** Create a professional README file documenting your spam detection analysis\n",
    "\n",
    "Based on your experimental results across all scenarios (SMS-only, email-only, cross-domain transfer, and combined datasets), create a comprehensive README.md file that summarizes your key findings, methodology, and performance comparisons. Include quantitative results, optimal preprocessing configurations, and practical deployment recommendations as you learned before."
   ],
   "id": "787170969ea4d0e"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
